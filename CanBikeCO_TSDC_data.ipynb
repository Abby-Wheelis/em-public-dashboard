{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "013ae92f",
   "metadata": {},
   "source": [
    "# TSDC Data Cleaning\n",
    "\n",
    "This notebook is set up to intake the files from the TSDC records and process them according to the data cleaning outlined in our paper\n",
    "\n",
    "MISSING 1 user and 1,272 trips! Not sure where they're getting missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ed2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a548cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "%store -r df_ei\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "%store -r dic_fuel\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_fuel = defaultdict(lambda: 'Other',dic_fuel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9386ed",
   "metadata": {},
   "source": [
    "## Mini Pilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2125c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_confirmed_trips = pd.read_csv('mini_pilot/data/analysis_confirmed_trip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ed4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(mini_confirmed_trips))\n",
    "print(mini_confirmed_trips.perno.nunique())\n",
    "# mini_confirmed_trips.columns\n",
    "\n",
    "#this is one more user and about 1,000 more trips than we had in our minipilot dataset \n",
    "## - but we haven't removed no labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4446b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2403\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "## remove trips with no label and count again\n",
    "labeled_mini = mini_confirmed_trips[mini_confirmed_trips.data_user_input_mode_confirm.notna()]\n",
    "labeled_mini = mini_confirmed_trips[mini_confirmed_trips.data_user_input_purpose_confirm.notna()]\n",
    "# labeled_mini = mini_confirmed_trips[mini_confirmed_trips.data_user_input_purpose_confirm.notna()]\n",
    "\n",
    "print(len(labeled_mini)) #only 25 over data used in paper\n",
    "print(labeled_mini.perno.nunique())#same as data used in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = labeled_mini.copy()\n",
    "\n",
    "#first, add the cleaned mode\n",
    "mini_data['Mode_confirm']= mini_data['data_user_input_mode_confirm'].map(dic_re)\n",
    "\n",
    "#second, add the cleaned replaced mode ASSUMES PROGRAM\n",
    "mini_data['Replaced_mode']= mini_data['data_user_input_replaced_mode'].map(dic_re)\n",
    "\n",
    "#third, add the cleaned purpose\n",
    "mini_data['Trip_purpose']= mini_data['data_user_input_purpose_confirm'].map(dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb50807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2354\n"
     ]
    }
   ],
   "source": [
    "# Combine variable categories\n",
    "mini_data = mini_data.replace('Gas Car, drove alone', 'Car')\n",
    "mini_data = mini_data.replace('Gas Car, with others', 'Shared Car')\n",
    "mini_data = mini_data.replace('Bikeshare', 'Shared Micromobility')\n",
    "mini_data = mini_data.replace('Scooter share', 'Shared Micromobility')\n",
    "mini_data = mini_data.replace('Regular Bike', 'Personal Micromobility')\n",
    "mini_data = mini_data.replace('Skate board', 'Personal Micromobility')\n",
    "mini_data = mini_data.replace('Train', 'Transit')\n",
    "mini_data = mini_data.replace('Free Shuttle', 'Transit')\n",
    "mini_data = mini_data.replace('Bus', 'Transit')\n",
    "mini_data = mini_data.replace('Walk', 'Walk')\n",
    "mini_data = mini_data.replace('Taxi/Uber/Lyft', 'Ridehail')\n",
    "mini_data = mini_data.replace('Pilot ebike', 'E-Bike')\n",
    "\n",
    "#filter out 'not a trip' trips\n",
    "mini_data = mini_data[~mini_data['Mode_confirm'].isin(['Not a Trip'])]\n",
    "mini_data = mini_data[~mini_data['Replaced_mode'].isin(['Not a Trip'])]\n",
    "mini_data = mini_data[~mini_data['Trip_purpose'].isin(['not_a_trip'])]\n",
    "\n",
    "print(len(mini_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90e0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data.loc[mini_data['Mode_confirm']=='Personal Micromobility', 'Mode_confirm'] = 'Other'\n",
    "mini_data.loc[mini_data['Mode_confirm']=='Shared Micromobility', 'Mode_confirm'] = 'Other'\n",
    "\n",
    "t1 = mini_data.groupby(['Mode_confirm'], as_index=False).count()[['Mode_confirm','data_distance']]\n",
    "t1['proportion'] = t1['data_distance'] / np.sum(t1.data_distance)\n",
    "t1['trip_type'] = 'All Trips'\n",
    "\n",
    "t2 = mini_data[mini_data['Trip_purpose']=='Work'].copy()\n",
    "t2 = t2.groupby(['Mode_confirm'], as_index=False).count()[['Mode_confirm','data_distance']]\n",
    "t2['proportion'] = t2['data_distance'] / np.sum(t2.data_distance)\n",
    "t2['trip_type'] = 'Work Trips'\n",
    "t2.loc[1.5] = 'Other', 0, 0, 'Work Trips'\n",
    "t2 = t2.sort_index().reset_index(drop=True)\n",
    "\n",
    "mini_data = pd.concat([t1,t2])\n",
    "mini_data['Dataset'] = 'Minipilot'\n",
    "mini_data.columns = ['Mode','Count','Proportion','Trip Type', \"Dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fccc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>Trip Type</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>477</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E-bike</td>\n",
       "      <td>776</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>28</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridehail</td>\n",
       "      <td>65</td>\n",
       "      <td>0.027613</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shared Car</td>\n",
       "      <td>685</td>\n",
       "      <td>0.290994</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transit</td>\n",
       "      <td>155</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walk</td>\n",
       "      <td>168</td>\n",
       "      <td>0.071368</td>\n",
       "      <td>All Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car</td>\n",
       "      <td>110</td>\n",
       "      <td>0.295699</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E-bike</td>\n",
       "      <td>134</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridehail</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shared Car</td>\n",
       "      <td>101</td>\n",
       "      <td>0.271505</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transit</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walk</td>\n",
       "      <td>23</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>Work Trips</td>\n",
       "      <td>Minipilot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mode  Count  Proportion   Trip Type    Dataset\n",
       "0         Car    477    0.202634   All Trips  Minipilot\n",
       "1      E-bike    776    0.329652   All Trips  Minipilot\n",
       "2       Other     28    0.011895   All Trips  Minipilot\n",
       "3    Ridehail     65    0.027613   All Trips  Minipilot\n",
       "4  Shared Car    685    0.290994   All Trips  Minipilot\n",
       "5     Transit    155    0.065845   All Trips  Minipilot\n",
       "6        Walk    168    0.071368   All Trips  Minipilot\n",
       "0         Car    110    0.295699  Work Trips  Minipilot\n",
       "1      E-bike    134    0.360215  Work Trips  Minipilot\n",
       "2       Other      0    0.000000  Work Trips  Minipilot\n",
       "3    Ridehail      1    0.002688  Work Trips  Minipilot\n",
       "4  Shared Car    101    0.271505  Work Trips  Minipilot\n",
       "5     Transit      3    0.008065  Work Trips  Minipilot\n",
       "6        Walk     23    0.061828  Work Trips  Minipilot"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_data #trip breakdown is really close to data used in paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb06aa",
   "metadata": {},
   "source": [
    "### matching minis to survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4538cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492\n",
      "15\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "mini_trips = pd.read_csv('mini_pilot/data/analysis_confirmed_trip.csv')\n",
    "# mini_trips = labeled_mini.copy()\n",
    "mini_surveys = pd.read_csv('mini_pilot/data/survey_household.csv')\n",
    "\n",
    "print(len(mini_trips))\n",
    "print(len(mini_surveys)) #15 surveys\n",
    "print(mini_trips.perno.nunique()) #13 unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ac3575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "socio_data = mini_surveys[~mini_surveys.perno.isnull()]\n",
    "print(len(socio_data))\n",
    "# socio_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d34339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['perno', 'timestamp'])\n",
    "socio_data.drop_duplicates(subset=['perno'], keep='last', inplace=True)\n",
    "socio_data['user_id_socio'] = socio_data.perno\n",
    "socio_data.user_id_socio = [i.replace('-','') for i in socio_data.user_id_socio] # remove all dashes from strings\n",
    "socio_data = socio_data.drop(labels='perno', axis=1)\n",
    "\n",
    "print(len(socio_data)) #same as number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8e7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "3662\n"
     ]
    }
   ],
   "source": [
    "# Lose some trips due to people with no survey responses\n",
    "mini_trips['user_id_socio'] = mini_trips.perno.astype(str)\n",
    "mini_trips.user_id_socio = [i.replace('-','') for i in mini_trips.user_id_socio] # remove all dashes from strings\n",
    "mini_trips = mini_trips.merge(socio_data, on='user_id_socio')\n",
    "\n",
    "print(mini_trips.user_id_socio.nunique()) #lost one person that has no survey record -- down to 12 people\n",
    "print(len(mini_trips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1237975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd27a69",
   "metadata": {},
   "source": [
    "## Full Pilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39bedae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##alternate survey prep - from the whole dataset\n",
    "\n",
    "# surveys = pd.read_csv('abby_ceo/survey_household_all.csv')\n",
    "# # surveys.unique_user_id_autofilled_do_not_edit.unique()\n",
    "\n",
    "# surveys = pd.read_csv('abby_ceo/survey_household_all.csv')\n",
    "# print(len(surveys), 'total surveys')\n",
    "\n",
    "# surveys = surveys[~surveys['unique_user_id_autofilled_do_not_edit'].isnull()]\n",
    "# print(len(surveys), 'surveys after dropping null ids')\n",
    "\n",
    "# surveys = surveys.sort_values(by=['unique_user_id_autofilled_do_not_edit', 'timestamp'])\n",
    "# surveys.drop_duplicates(subset=['unique_user_id_autofilled_do_not_edit'], keep='last', inplace=True)\n",
    "# print(len(surveys),'surveys', surveys['unique_user_id_autofilled_do_not_edit'].nunique(), 'users after dropping duplicates')\n",
    "\n",
    "# #prepare survey ids for merging\n",
    "# surveys['user_id_socio'] = surveys['unique_user_id_autofilled_do_not_edit'].astype(str)\n",
    "# surveys['user_id_socio'] = surveys['user_id_socio'].str.strip() #remove leading or trailing whitespace!!\n",
    "# surveys = surveys.drop(labels='unique_user_id_autofilled_do_not_edit', axis=1)\n",
    "\n",
    "# print(surveys.user_id_socio.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d027a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with  4c\n",
      "10121 trips\n",
      "14 people\n",
      "28 surveys\n",
      "28 surveys after dropping null ids\n",
      "15 surveys 15 users after dropping duplicates\n",
      "8874 trips after merging\n",
      "13 people after merging\n",
      "starting with  cc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/2570610314.py:9: DtypeWarning: Columns (27,28,29,30,31,33,34,36,43,44,45,46,47,49,50,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips = pd.read_csv('abby_ceo/' + program + '/analysis_confirmed_trip.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75199 trips\n",
      "64 people\n",
      "72 surveys\n",
      "72 surveys after dropping null ids\n",
      "50 surveys 50 users after dropping duplicates\n",
      "72260 trips after merging\n",
      "47 people after merging\n",
      "starting with  fc\n",
      "32442 trips\n",
      "30 people\n",
      "47 surveys\n",
      "47 surveys after dropping null ids\n",
      "30 surveys 30 users after dropping duplicates\n",
      "32341 trips after merging\n",
      "29 people after merging\n",
      "starting with  pc\n",
      "51196 trips\n",
      "39 people\n",
      "65 surveys\n",
      "65 surveys after dropping null ids\n",
      "39 surveys 39 users after dropping duplicates\n",
      "50693 trips after merging\n",
      "38 people after merging\n",
      "starting with  sc\n",
      "17989 trips\n",
      "22 people\n",
      "29 surveys\n",
      "29 surveys after dropping null ids\n",
      "15 surveys 15 users after dropping duplicates\n",
      "15565 trips after merging\n",
      "14 people after merging\n",
      "starting with  vail_22\n",
      "9133 trips\n",
      "12 people\n",
      "11 surveys\n",
      "11 surveys after dropping null ids\n",
      "9 surveys 9 users after dropping duplicates\n",
      "7447 trips after merging\n",
      "9 people after merging\n"
     ]
    }
   ],
   "source": [
    "#loop over\n",
    "programs = ['4c', 'cc', 'fc', 'pc', 'sc', 'vail_22']\n",
    "datasets = []\n",
    "\n",
    "for program in programs:\n",
    "    print('starting with ', program)\n",
    "    \n",
    "    #create dataset with surveys and trips\n",
    "    trips = pd.read_csv('abby_ceo/' + program + '/analysis_confirmed_trip.csv')\n",
    "    print(len(trips), 'trips')\n",
    "    print(trips.perno.nunique(), 'people')\n",
    "\n",
    "    surveys = pd.read_csv('abby_ceo/' + program + '/' + program + '_survey_household.csv')\n",
    "    print(len(surveys), 'surveys')\n",
    "\n",
    "    #drop any null ids\n",
    "    socio_data = surveys[~surveys['unique_user_id_autofilled_do_not_edit'].isnull()]\n",
    "    print(len(socio_data), 'surveys after dropping null ids')\n",
    "\n",
    "    #drop duplicates\n",
    "    socio_data = socio_data.sort_values(by=['unique_user_id_autofilled_do_not_edit', 'timestamp'])\n",
    "    socio_data.drop_duplicates(subset=['unique_user_id_autofilled_do_not_edit'], keep='last', inplace=True)\n",
    "    print(len(socio_data),'surveys', socio_data['unique_user_id_autofilled_do_not_edit'].nunique(), 'users after dropping duplicates')\n",
    "\n",
    "    #prepare survey ids for merging\n",
    "    socio_data['user_id_socio'] = socio_data['unique_user_id_autofilled_do_not_edit'].astype(str)\n",
    "    socio_data['user_id_socio'] = socio_data['user_id_socio'].str.strip() #remove leading or trailing whitespace!!\n",
    "    socio_data['user_id_socio'] = socio_data['user_id_socio']\n",
    "    socio_data = socio_data.drop(labels='unique_user_id_autofilled_do_not_edit', axis=1)\n",
    "\n",
    "    #prepare trip ids for merging\n",
    "    trips['user_id_socio'] = trips.perno.astype(str)\n",
    "    trips['user_id_socio'] = trips['user_id_socio'].str.strip() #remove leading or trailing whitespace!!\n",
    "    trips.user_id_socio = [i.replace('-','') for i in trips.user_id_socio] # remove all dashes from strings\n",
    "\n",
    "    #merge the data\n",
    "    data = trips.merge(socio_data, on='user_id_socio')\n",
    "    print(len(data), 'trips after merging')\n",
    "    print(data.user_id_socio.nunique(), 'people after merging')\n",
    "    \n",
    "    data['program'] = program.split('_')[0]\n",
    "    \n",
    "    #add to list of datasets\n",
    "    datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5179563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187180 trips\n",
      "150 users\n"
     ]
    }
   ],
   "source": [
    "#merge them all together\n",
    "full_data = pd.concat(datasets)\n",
    "print(len(full_data), 'trips')\n",
    "print(full_data.perno.nunique(), 'users')\n",
    "\n",
    "# data = full_data.merge(surveys, on='user_id_socio')\n",
    "# print(len(data), 'trips after merging with surveys')\n",
    "# print(data.user_id_socio.nunique(), 'people after merging with surveys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4b72afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_ids = full_data.user_id_socio.unique()\n",
    "# survey_ids = surveys.user_id_socio.unique()\n",
    "# for id in survey_ids:\n",
    "#     if id not in trip_ids:\n",
    "#         print(id)\n",
    "\n",
    "## some surveys don't have trips, some trips don't have surveys..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7958297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73993 labeled trips\n",
      "143 users who labeled\n"
     ]
    }
   ],
   "source": [
    "#filter out unlabeled trips\n",
    "labeled_data = full_data[full_data.data_user_input_mode_confirm.notna()]\n",
    "labeled_data = labeled_data[labeled_data.data_user_input_purpose_confirm.notna()]\n",
    "\n",
    "print(len(labeled_data), 'labeled trips')\n",
    "print(labeled_data.user_id_socio.nunique(), 'users who labeled')         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4826b",
   "metadata": {},
   "source": [
    "so far so good, we're looking for at least 122 users and at least 61,496 trips after ALL cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd2824b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data.rename(columns={'user_id_socio':'user_id',\n",
    "                          'please_identify_which_category_represents_your_total_household_':'HHINC',\n",
    "                          'how_many_motor_vehicles_are_owned_leased_or_available_for_regul':'VEH',\n",
    "                            ' how_many_motor_vehicles_are_owned_leased_or_available_for_regul':'VEH',\n",
    "                             'how_many_motor_vehicles_are_owned_leased_or_available_for_regul ':'VEH',\n",
    "                           'in_which_year_were_you_born?':'AGE',\n",
    "                          'including_yourself_how_many_people_live_in_your_home?':'HHSIZE',\n",
    "                          'how_many_children_under_age_18_live_in_your_home?':'CHILDREN',\n",
    "                          'what_is_your_gender?':'GENDER',\n",
    "                          'if_you_were_unable_to_use_your_household_vehicles_which_of_the_':'available_modes',\n",
    "                          'are_you_a_student?':'STUDENT',\n",
    "                         'data_duration':'duration', \n",
    "                         'data_distance':'distance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa0a6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labeled_data.copy()\n",
    "\n",
    "#first, add the cleaned mode\n",
    "data['Mode_confirm']= data['data_user_input_mode_confirm'].map(dic_re)\n",
    "\n",
    "#second, add the cleaned replaced mode ASSUMES PROGRAM\n",
    "data['Replaced_mode']= data['data_user_input_replaced_mode'].map(dic_re)\n",
    "\n",
    "#third, add the cleaned purpose\n",
    "data['Trip_purpose']= data['data_user_input_purpose_confirm'].map(dic_pur)\n",
    "\n",
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'data_start_local_dt_year':'year','data_start_local_dt_month':'month','data_start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "\n",
    "# Fix age (birth year to age)\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Number of workers (size of HH - kids)\n",
    "data['WORKERS'] = data['HHSIZE'] - data['CHILDREN']\n",
    "\n",
    "# Duration in minutes (hours to minutes)\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# duration in miles (meters to miles)\n",
    "data['distance'] = data['distance'] / 1609.34\n",
    "\n",
    "# E-bike/not E-Bike variable\n",
    "data['is_ebike'] = \"E-Bike Trips\"\n",
    "data.loc[data['Mode_confirm']!=\"E-bike\", 'is_ebike'] = \"Non E-Bike Trips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38324a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "44\n",
      "27\n",
      "36\n",
      "14\n",
      "9\n",
      "3496\n",
      "27673\n",
      "11701\n",
      "17535\n",
      "8385\n",
      "5203\n"
     ]
    }
   ],
   "source": [
    "#separating programs\n",
    "four_corners = data[data.program == \"4c\"]\n",
    "community_cycles = data[data.program == \"cc\"]\n",
    "fort_collins = data[data.program == \"fc\"]\n",
    "pueblo = data[data.program == \"pc\"]\n",
    "smart_commute = data[data.program == \"sc\"]\n",
    "vail = data[data.program == \"vail\"]\n",
    "\n",
    "print(four_corners['user_id'].nunique())\n",
    "print(community_cycles['user_id'].nunique())\n",
    "print(fort_collins['user_id'].nunique())\n",
    "print(pueblo['user_id'].nunique())\n",
    "print(smart_commute['user_id'].nunique())\n",
    "print(vail['user_id'].nunique())\n",
    "\n",
    "print(len(four_corners))\n",
    "print(len(community_cycles))\n",
    "print(len(fort_collins))\n",
    "print(len(pueblo))\n",
    "print(len(smart_commute))\n",
    "print(len(vail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc12fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73993\n",
      "143\n",
      "66837\n",
      "132\n",
      "66837\n",
      "132\n",
      "66837\n",
      "132\n",
      "66837\n",
      "132\n",
      "66837\n",
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/1252728773.py:45: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data.mode_confirm = pd.Categorical(data.data_user_input_mode_confirm, ordered=True, categories=np.unique(list(dic_re.keys())))\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "#records that had ’prefer not to say’ as a response for household income, household vehicles, and other available modes\n",
    "data = data[~data['HHINC'].isin(['Prefer not to say'])]\n",
    "data = data[~data['VEH'].isin(['Prefer not to say / Prefiero no decir.'])]\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "data['HHINC_NUM'] = data.HHINC.replace(['Less than $24,999',\n",
    "                                       '$25,000-$49,999',\n",
    "                                       '$50,000-$99,999',\n",
    "                                       '$100,000 -$149,999',\n",
    "                                       '$150,000-$199,999',\n",
    "                                       '$200,000 or more'], [12500,37500,75000,125000,175000,250000])\n",
    "\n",
    "# Calculate average income per adult in the household\n",
    "data['PINC'] = data['HHINC_NUM'] / data['WORKERS']\n",
    "\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "# Combine variable categories\n",
    "data = data.replace('Gas Car, drove alone', 'Car')\n",
    "data = data.replace('Gas Car, with others', 'Shared Car')\n",
    "data = data.replace('Bikeshare', 'Shared Micromobility')\n",
    "data = data.replace('Scooter share', 'Shared Micromobility')\n",
    "data = data.replace('Regular Bike', 'Personal Micromobility')\n",
    "data = data.replace('Skate board', 'Personal Micromobility')\n",
    "data = data.replace('Train', 'Transit')\n",
    "data = data.replace('Free Shuttle', 'Transit')\n",
    "data = data.replace('Bus', 'Transit')\n",
    "data = data.replace('Walk', 'Walk')\n",
    "data = data.replace('Taxi/Uber/Lyft', 'Ridehail')\n",
    "data = data.replace('Pilot ebike', 'E-Bike')\n",
    "\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "# Categorical type will include all days/modes in groupby even if there is no data for a particular tabulation\n",
    "data.user_id = pd.Categorical(data.user_id)\n",
    "data.date_time = pd.Categorical(data.date_time)\n",
    "data.mode_confirm = pd.Categorical(data.data_user_input_mode_confirm, ordered=True, categories=np.unique(list(dic_re.keys())))\n",
    "\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "# Add order to categorical variables\n",
    "data.HHINC = pd.Categorical(data.HHINC, ordered=True)\n",
    "data['Mode'] = pd.Categorical(data.Mode_confirm, ordered=True, categories=[\n",
    "    'E-bike',\n",
    "    'Car',\n",
    "    'Shared Car',\n",
    "    'Walk',\n",
    "    'Transit',\n",
    "    'Personal Micromobility',\n",
    "    'Shared Micromobility',\n",
    "    'Ridehail',\n",
    "    'Other'])\n",
    "data.VEH = data.VEH.astype(str)\n",
    "data.VEH = pd.Categorical(data.VEH, ordered=True, categories=['0','1','2','3','4+'])\n",
    "data['PINC_NUM'] = data['PINC']\n",
    "data.PINC = pd.cut(data.PINC, bins=[0,10000,20000,30000,40000,50000,60000,70000,999999],\n",
    "                  labels=[\"$0-9\",\n",
    "                         \"$10-19\",\n",
    "                         \"$20-29\",\n",
    "                         \"$30-39\",\n",
    "                         \"$40-49\",\n",
    "                         \"$50-59\",\n",
    "                         \"$60-69\",\n",
    "                         \"$70+\"])\n",
    "\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b24ee383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "41\n",
      "25\n",
      "33\n",
      "14\n",
      "8\n",
      "2752\n",
      "25822\n",
      "11618\n",
      "13622\n",
      "8385\n",
      "4638\n"
     ]
    }
   ],
   "source": [
    "#separating programs\n",
    "four_corners = data[data.program == \"4c\"]\n",
    "community_cycles = data[data.program == \"cc\"]\n",
    "fort_collins = data[data.program == \"fc\"]\n",
    "pueblo = data[data.program == \"pc\"]\n",
    "smart_commute = data[data.program == \"sc\"]\n",
    "vail = data[data.program == \"vail\"]\n",
    "\n",
    "print(four_corners['user_id'].nunique())\n",
    "print(community_cycles['user_id'].nunique())\n",
    "print(fort_collins['user_id'].nunique())\n",
    "print(pueblo['user_id'].nunique())\n",
    "print(smart_commute['user_id'].nunique())\n",
    "print(vail['user_id'].nunique())\n",
    "\n",
    "print(len(four_corners))\n",
    "print(len(community_cycles))\n",
    "print(len(fort_collins))\n",
    "print(len(pueblo))\n",
    "print(len(smart_commute))\n",
    "print(len(vail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7269e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66837\n",
      "132\n",
      "66689\n",
      "132\n",
      "65864\n",
      "132\n",
      "64648\n",
      "130\n",
      "64479\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "#filtered out ages that were greater than 100\n",
    "data = data[data['AGE'] < 100]\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "#filter out durations longer than 8 hours\n",
    "data = data[data['duration']<480]\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "#distances more than 50 miles \n",
    "data = data[data['distance']<50]\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "#filter household sizes smaller than the number of kids\n",
    "data = data[data['HHSIZE']>data['CHILDREN']]\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())\n",
    "\n",
    "#filter out households greater than 10\n",
    "data = data[data['HHSIZE']<10]\n",
    "print(len(data))\n",
    "print(data.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f547dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62699 trips after filtering\n",
      "129 users after filtering\n"
     ]
    }
   ],
   "source": [
    "# Vehicles per driver\n",
    "data = data[data['VEH'].notna()] #vails VEH nums were not strings?\n",
    "data['VEH_num'] = data['VEH'].replace(['1','2','3','4+'],[1,2,3,4]).astype(int)\n",
    "data['DRIVERS'] = data[\"including_yourself_how_many_people_have_a_driver's_license_in_y\"]\n",
    "data['DRIVERS_num'] = data['DRIVERS'].replace\n",
    "data['veh_per_driver'] = (data['VEH_num'] / data['DRIVERS']).fillna(0)\n",
    "data.loc[data['veh_per_driver']==np.inf, 'veh_per_driver'] = 0\n",
    "\n",
    "#filter out 'not a trip' trips\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip'])]\n",
    "data = data[~data['Replaced_mode'].isin(['Not a Trip'])]\n",
    "data = data[~data['Trip_purpose'].isin(['not_a_trip'])]\n",
    "\n",
    "print(len(data), 'trips after filtering') #around 63,000\n",
    "print(data.user_id.nunique(), 'users after filtering') #132 it sounds like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3da64",
   "metadata": {},
   "source": [
    "# filtering out trips before first e-bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef573862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4c', 'cc', 'fc', 'pc', 'sc', 'vail'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.program.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2762330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'data_start_ts':'start_ts'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf89748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "41\n",
      "25\n",
      "32\n",
      "13\n",
      "8\n",
      "2506\n",
      "25071\n",
      "10925\n",
      "13020\n",
      "6860\n",
      "4317\n"
     ]
    }
   ],
   "source": [
    "#separating programs\n",
    "four_corners = data[data.program == \"4c\"]\n",
    "community_cycles = data[data.program == \"cc\"]\n",
    "fort_collins = data[data.program == \"fc\"]\n",
    "pueblo = data[data.program == \"pc\"]\n",
    "smart_commute = data[data.program == \"sc\"]\n",
    "vail = data[data.program == \"vail\"]\n",
    "\n",
    "print(four_corners['user_id'].nunique())\n",
    "print(community_cycles['user_id'].nunique())\n",
    "print(fort_collins['user_id'].nunique())\n",
    "print(pueblo['user_id'].nunique())\n",
    "print(smart_commute['user_id'].nunique())\n",
    "print(vail['user_id'].nunique())\n",
    "\n",
    "print(len(four_corners))\n",
    "print(len(community_cycles))\n",
    "print(len(fort_collins))\n",
    "print(len(pueblo))\n",
    "print(len(smart_commute))\n",
    "print(len(vail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9e7e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering each of them\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50b8a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/3643144510.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  smart_commute['start_ts']= pd.to_datetime(smart_commute['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#smart commute filtering\n",
    "\n",
    "#timestamp conversion\n",
    "smart_commute['start_ts']= pd.to_datetime(smart_commute['start_ts'], utc=True, unit='s')\n",
    "\n",
    "#grouping, counting unique users\n",
    "trip_sep=smart_commute.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep['user_id'].nunique())\n",
    "\n",
    "#consider only trips with E-bike (to get first e-bike trip)\n",
    "sc_ebike_first=trip_sep[trip_sep['Mode_confirm']=='E-bike']\n",
    "\n",
    "#get all the trips by ysers who ever had an e-bike trip\n",
    "sc_ebike_user_list= sc_ebike_first['user_id'].tolist()\n",
    "smart_commute_incl_ebike = smart_commute[smart_commute['user_id'].isin(sc_ebike_user_list)]\n",
    "print(smart_commute_incl_ebike['user_id'].nunique())\n",
    "\n",
    "#filter to the earliest ebike trip\n",
    "for unique_id in sc_ebike_first['user_id']:\n",
    "    for date in sc_ebike_first['start_ts']:\n",
    "        smart_commute_ebike_first=smart_commute_incl_ebike[(smart_commute_incl_ebike['start_ts'] >= date)]\n",
    "\n",
    "sc_unique_ebikefirst=smart_commute_ebike_first['user_id'].unique()\n",
    "print(smart_commute_ebike_first['user_id'].nunique()) #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ac368a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/4259660508.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  four_corners['start_ts']= pd.to_datetime(four_corners['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#filter four corners\n",
    "four_corners['start_ts']= pd.to_datetime(four_corners['start_ts'], utc=True, unit='s')\n",
    "\n",
    "trip_sep_fc=four_corners.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep_fc['user_id'].nunique())\n",
    "\n",
    "fc_ebike_first=trip_sep_fc[trip_sep_fc['Mode_confirm']=='E-bike']\n",
    "\n",
    "fc_ebike_user_list= fc_ebike_first['user_id'].tolist()\n",
    "four_corners_incl_ebike = four_corners[four_corners['user_id'].isin(fc_ebike_user_list)]\n",
    "print(four_corners_incl_ebike['user_id'].nunique())\n",
    "\n",
    "for unique_id in fc_ebike_first['user_id']:\n",
    "    for date in fc_ebike_first['start_ts']:\n",
    "        four_corners_ebike_first=four_corners_incl_ebike[(four_corners_incl_ebike['start_ts'] >= date)]\n",
    "        \n",
    "fc_unique_ebikefirst=four_corners_ebike_first['user_id'].unique()\n",
    "print(four_corners_ebike_first['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "339f12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/1138286727.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  community_cycles['start_ts']= pd.to_datetime(community_cycles['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "#filtering community cycles\n",
    "community_cycles['start_ts']= pd.to_datetime(community_cycles['start_ts'], utc=True, unit='s')\n",
    "\n",
    "trip_sep_cc=community_cycles.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep_cc['user_id'].nunique())\n",
    "\n",
    "cc_ebike_first=trip_sep_cc[trip_sep_cc['Mode_confirm']=='E-bike']\n",
    "\n",
    "cc_ebike_user_list= cc_ebike_first['user_id'].tolist()\n",
    "community_cycles_incl_ebike = community_cycles[community_cycles['user_id'].isin(cc_ebike_user_list)]\n",
    "print(community_cycles_incl_ebike['user_id'].nunique())\n",
    "\n",
    "for unique_id in cc_ebike_first['user_id']:\n",
    "    for date in cc_ebike_first['start_ts']:\n",
    "        community_cycles_ebike_first=community_cycles_incl_ebike[(community_cycles_incl_ebike['start_ts'] >= date)]\n",
    "\n",
    "cc_unique_ebikefirst=community_cycles_ebike_first['user_id'].unique()\n",
    "print(community_cycles_ebike_first['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa670a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/1774079327.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fort_collins['start_ts']= pd.to_datetime(fort_collins['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "#filtering fort collins\n",
    "fort_collins['start_ts']= pd.to_datetime(fort_collins['start_ts'], utc=True, unit='s')\n",
    "\n",
    "trip_sep_fc=fort_collins.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep_fc['user_id'].nunique())\n",
    "\n",
    "fc_ebike_first=trip_sep_fc[trip_sep_fc['Mode_confirm']=='E-bike']\n",
    "\n",
    "fc_ebike_user_list= fc_ebike_first['user_id'].tolist()\n",
    "fort_collins_incl_ebike = fort_collins[fort_collins['user_id'].isin(fc_ebike_user_list)]\n",
    "print(fort_collins_incl_ebike['user_id'].nunique())\n",
    "\n",
    "for unique_id in fc_ebike_first['user_id']:\n",
    "    for date in fc_ebike_first['start_ts']:\n",
    "        fort_collins_ebike_first=fort_collins_incl_ebike[(fort_collins_incl_ebike['start_ts'] >= date)]\n",
    "        \n",
    "fc_unique_ebikefirst=fort_collins_ebike_first['user_id'].unique()\n",
    "print(fort_collins_ebike_first['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "105bd88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/950012586.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pueblo['start_ts']= pd.to_datetime(pueblo['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "#filtering pueblo\n",
    "pueblo['start_ts']= pd.to_datetime(pueblo['start_ts'], utc=True, unit='s')\n",
    "\n",
    "trip_sep_pu=pueblo.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep_pu['user_id'].nunique())\n",
    "\n",
    "pu_ebike_first=trip_sep_pu[trip_sep_pu['Mode_confirm']=='E-bike']\n",
    "\n",
    "pu_ebike_user_list= pu_ebike_first['user_id'].tolist()\n",
    "pueblo_incl_ebike = pueblo[pueblo['user_id'].isin(pu_ebike_user_list)]\n",
    "print(pueblo_incl_ebike['user_id'].nunique())\n",
    "\n",
    "for unique_id in pu_ebike_first['user_id']:\n",
    "    for date in pu_ebike_first['start_ts']:\n",
    "        pueblo_ebike_first=pueblo_incl_ebike[(pueblo_incl_ebike['start_ts'] >= date)]\n",
    "        \n",
    "pu_unique_ebikefirst=pueblo_ebike_first['user_id'].unique()\n",
    "print(pueblo_ebike_first['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd3e079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190/3916199498.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vail['start_ts']= pd.to_datetime(vail['start_ts'], utc=True, unit='s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#filtering vail\n",
    "vail['start_ts']= pd.to_datetime(vail['start_ts'], utc=True, unit='s')\n",
    "\n",
    "trip_sep_va=vail.groupby(['user_id','Mode_confirm']).apply(lambda x:x[x.start_ts==min(x.start_ts)])\n",
    "print(trip_sep_va['user_id'].nunique())\n",
    "\n",
    "va_ebike_first=trip_sep_va[trip_sep_va['Mode_confirm']=='E-bike']\n",
    "\n",
    "va_ebike_user_list= va_ebike_first['user_id'].tolist()\n",
    "vail_incl_ebike = vail[vail['user_id'].isin(va_ebike_user_list)]\n",
    "print(vail_incl_ebike['user_id'].nunique())\n",
    "\n",
    "for unique_id in va_ebike_first['user_id']:\n",
    "    for date in va_ebike_first['start_ts']:\n",
    "        vail_ebike_first=vail_incl_ebike[(vail_incl_ebike['start_ts'] >= date)]\n",
    "        \n",
    "va_unique_ebikefirst=vail_ebike_first['user_id'].unique()\n",
    "print(vail_ebike_first['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3d74525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4c 10 1398\n",
      "cc 41 24820\n",
      "fc 22 10635\n",
      "pc 29 12570\n",
      "sc 11 6491\n",
      "vail 8 4310\n"
     ]
    }
   ],
   "source": [
    "#checking num users and num trips in each program\n",
    "## num users is perfect\n",
    "print('4c', four_corners_ebike_first['user_id'].nunique(), len(four_corners_ebike_first))\n",
    "print('cc', community_cycles_ebike_first['user_id'].nunique(), len(community_cycles_ebike_first))\n",
    "print('fc', fort_collins_ebike_first['user_id'].nunique(), len(fort_collins_ebike_first))\n",
    "print('pc', pueblo_ebike_first['user_id'].nunique(), len(pueblo_ebike_first))\n",
    "print('sc', smart_commute_ebike_first['user_id'].nunique(), len(smart_commute_ebike_first))\n",
    "print('vail', vail_ebike_first['user_id'].nunique(), len(vail_ebike_first))\n",
    "\n",
    "## num trips needs some work -- 4c is under and the rest are over ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d24cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60224\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "#combining the filtered datasets\n",
    "filtered_merged = pd.concat([four_corners_ebike_first, community_cycles_ebike_first, fort_collins_ebike_first, \n",
    "                             pueblo_ebike_first, smart_commute_ebike_first,vail_ebike_first], axis=0)\n",
    "print(len(filtered_merged)) #\n",
    "print(filtered_merged['user_id'].nunique()) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b5e0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.049814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.644487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.121165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.148001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.941898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>479.495935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration\n",
       "count  60224.000000\n",
       "mean      24.049814\n",
       "std       30.644487\n",
       "min        0.000068\n",
       "25%        9.121165\n",
       "50%       15.148001\n",
       "75%       27.941898\n",
       "max      479.495935"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics table\n",
    "print(len(pd.unique(filtered_merged.user_id)))\n",
    "stat_data = filtered_merged[['duration']]\n",
    "stat_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a csv, to be used as input to analysis!\n",
    "filtered_merged.to_csv(\"tsdc_filtered_merged_trips.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
